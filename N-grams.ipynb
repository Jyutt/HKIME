{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated on Mon Dec 23 02:13:05 2019 UTC\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print(f\"Last updated on {time.asctime(time.gmtime())} UTC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose\n",
    "\n",
    "This notebook would serve to show the design process of the Back-off n-grams Language Models (BNLM) with enhancement from Neural Network Language Models (NNLM) as described the paper \"Neural Network Language Model for Chinese Pinyin Input Method Engine\" by Chen et all. The task at hand with this language model is given a sequence of syllables, to predict which is most likely the next syllable, a task also known as candidate sentence generation. The model is to be implemented into HKIME, an intelligent input method for Cantonese. There would be three sections in this notebook, each building upon the previous. \n",
    "\n",
    "### Breakdown\n",
    "\n",
    "- Section 1: Basic n-grams prediction model\n",
    "- Section 2: Back-off n-grams language model with interpolated Kneser-Ney smoothing\n",
    "- Section 3: BNLM (from section 2) with probabilities calculated with NNLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jyutping Corpus Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Add corpus processing\n",
    "#TODO: Find better corpuses\n",
    "#TODO: Look into webscraping to generate corpuses ourselves\n",
    "jyutping_corpus = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: basic n-grams prediction model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post-processing of the cantonese corpus would get us a list of strings, where each string could be a phrase, a sentence, or a paragraph. For conciseness, we would call all of these sentences. In this section, we would divide up each sentence into the n-grams and then store the possible next letters for each n-gram in a python dictionary. The naive prediction algorithm would randomly pick from the possible next letters given a certain n-gram to generate candidate sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set n-grams character count (the n in n-grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHARACTER_COUNT = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating n-grams dictionary\n",
    "\n",
    "This would generate a dictionary where each key is an n-gram and the value would be a list of possible next characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns dictionary for prediction\n",
    "def generate_n_grams_dict(processed_corpus):\n",
    "    result = dict()\n",
    "    for sentence in processed_corpus:\n",
    "        #i is the start index of the slice\n",
    "        for i in range(len(sentence) - CHARACTER_COUNT - 1): #-1 since last slice does not have next char\n",
    "            grams = sentence[i:i+CHARACTER_COUNT]\n",
    "            next_char = sentence[i+CHARACTER_COUNT]\n",
    "            if grams in result:\n",
    "                result[grams].append(next_char)\n",
    "            else:\n",
    "                #as long as there is an n-gram key in the dict, there would be at least one next char\n",
    "                result[grams] = [next_char] \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: visualization of n-grams dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Model\n",
    "\n",
    "This naive prediction model would, if the sentence has an n-gram in the dictionary, randomly select a next character from the list of potential next characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns a next character given an n_grams_dict and a sentence.\n",
    "def predict_next_char(n_grams_dict, sentence):\n",
    "    potentials = n_gram_dict.get(sentence[-CHARACTER_COUNT:], None)\n",
    "    return random.choice(potentials) if potentials != None else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "Here we would test the implementation of the naive n-grams prediction model, for comparison with more sophisticated language models. We would do two tests, the first one would generate a 200 character sentence, and the second would test the implementation analytically by seeing how many next characters it will predict correctly on the test dataset.\n",
    "\n",
    "TODO: Add a validation dataset. The current corpus is too small to be used both for training and validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(sentence):\n",
    "    n_grams_dict = generate_n_grams_dict(jyutping_corpus)\n",
    "    tmp = sentence\n",
    "    #Generate a sentence of up to 200 characters, will break if an n-gram not found in n-grams dict.\n",
    "    for i in range(200):\n",
    "        res = predict_next_char(n_grams_dict, tmp)\n",
    "        if res == None:\n",
    "            break\n",
    "        else:\n",
    "            tmp = tmp + res\n",
    "    return tmp\n",
    "\n",
    "#testing(\"(leihou chinese characters)\")\n",
    "#testing(\"(mgoi chinese characters)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 0 predictions made\n",
      "0 predictions correct\n",
      "Prediction accuracy: 0.0%\n"
     ]
    }
   ],
   "source": [
    "n_grams_dict = generate_n_grams_dict(jyutping_corpus)\n",
    "count = 0\n",
    "correct = 0\n",
    "for sentence in jyutping_corpus:\n",
    "    for i in range(len(sentence) - CHARACTER_COUNT - 1):\n",
    "        if predict_next_char(n_grams_dict, sentence[:i+CHARACTER_COUNT]) == sentence[i+CHARACTER_COUNT]:\n",
    "            correct += 1\n",
    "        count += 1\n",
    "\n",
    "print(f\"Total of {count} predictions made\")\n",
    "print(f\"{correct} predictions correct\")\n",
    "print(f\"Prediction accuracy: {correct/(count+1)}%\") #TODO: Remove the +1 after there is content in the jyutping_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Back-off n-grams language model with interpolated Kneser-Ney smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
